{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from -r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (3.8.3)\n",
      "Requirement already satisfied: pandas in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from -r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: autokeras in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from -r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from pandas->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from pandas->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: keras-tuner>=1.4.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (1.4.7)\n",
      "Requirement already satisfied: keras-nlp>=0.8.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (3.3.3)\n",
      "Requirement already satisfied: dm-tree in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.1.8)\n",
      "Requirement already satisfied: absl-py in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: rich in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.0.8)\n",
      "Requirement already satisfied: h5py in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (3.11.0)\n",
      "Requirement already satisfied: optree in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.3.2)\n",
      "Requirement already satisfied: keras-core in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.1.7)\n",
      "Requirement already satisfied: regex in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2023.12.25)\n",
      "Requirement already satisfied: kagglehub in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.2.4)\n",
      "Requirement already satisfied: tensorflow-text in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.16.1)\n",
      "Requirement already satisfied: requests in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras-tuner>=1.4.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from keras-tuner>=1.4.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (1.0.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from kagglehub->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from optree->keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from requests->keras-tuner>=1.4.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from requests->keras-tuner>=1.4.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from requests->keras-tuner>=1.4.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from requests->keras-tuner>=1.4.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.17.2)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (69.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.36.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.43.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/fabio/venvs/my_venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp>=0.8.0->autokeras->-r /home/fabio/Mestrado/Eng-Aprendizado-Maquina/requirements/requirements_ap8.txt (line 3)) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "requirements_filename = 'requirements_ap8.txt'\n",
    "if str(pathlib.Path().resolve().name) == \"notebooks\":\n",
    "    root = str(pathlib.Path().resolve().parent.parent)+'/'\n",
    "    sys.path.append(root)\n",
    "    requirements_path = root + 'requirements/'+requirements_filename\n",
    "else:\n",
    "    ! git clone --branch ap8 https://github.com/Fabio-Trindade/Eng-Aprendizado-Maquina.git\n",
    "    root = str(pathlib.Path().resolve()) +'/'\n",
    "    src_path = root + '/Eng-Aprendizado-Maquina/'\n",
    "    requirements_path = src_path + 'requirements/'+requirements_filename\n",
    "    sys.path.append(root + '/Eng-Aprendizado-Maquina/')\n",
    "\n",
    "! pip install -r $requirements_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.util_read_file import UtilReadFile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils.util_pre_processor import UtilPreProcessor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src.utils.util_path import UtilPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo *Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = UtilPath.get_root_path() + '/'\n",
    "df = UtilReadFile.read_csv_with_pandas(root+'datasets/churn_bank.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo Dados de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Geography',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = ['CreditScore', 'Geography',\n",
    "        'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "        'IsActiveMember', 'EstimatedSalary']\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Exited']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column = ['Exited']\n",
    "target_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando os dados categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Geography', 'Gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando os dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tenure',\n",
       " 'Balance',\n",
       " 'Age',\n",
       " 'IsActiveMember',\n",
       " 'CreditScore',\n",
       " 'HasCrCard',\n",
       " 'EstimatedSalary',\n",
       " 'NumOfProducts']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns = list(set(feature_columns) - set(categorical_columns))\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engenharia de atributos - Dados Numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>0.538</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>0.516</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>0.304</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>0.698</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>0.842</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>0.332</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>10</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>0.718</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>0.844</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>0.884</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  \\\n",
       "0             1    15634602   Hargrave        0.538    France  Female   \n",
       "1             2    15647311       Hill        0.516     Spain  Female   \n",
       "2             3    15619304       Onio        0.304    France  Female   \n",
       "3             4    15701354       Boni        0.698    France  Female   \n",
       "4             5    15737888   Mitchell        1.000     Spain  Female   \n",
       "...         ...         ...        ...          ...       ...     ...   \n",
       "9995       9996    15606229   Obijiaku        0.842    France    Male   \n",
       "9996       9997    15569892  Johnstone        0.332    France    Male   \n",
       "9997       9998    15584532        Liu        0.718    France  Female   \n",
       "9998       9999    15682355  Sabbatini        0.844   Germany    Male   \n",
       "9999      10000    15628319     Walker        0.884    France  Female   \n",
       "\n",
       "           Age  Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     0.324324       2  0.000000              1          1               1   \n",
       "1     0.310811       1  0.334031              1          0               1   \n",
       "2     0.324324       8  0.636357              3          1               0   \n",
       "3     0.283784       1  0.000000              2          0               0   \n",
       "4     0.337838       2  0.500246              1          1               1   \n",
       "...        ...     ...       ...            ...        ...             ...   \n",
       "9995  0.283784       5  0.000000              2          1               0   \n",
       "9996  0.229730      10  0.228657              1          1               1   \n",
       "9997  0.243243       7  0.000000              1          0               1   \n",
       "9998  0.324324       3  0.299226              2          1               0   \n",
       "9999  0.135135       4  0.518708              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0            0.506735       1  \n",
       "1            0.562709       0  \n",
       "2            0.569654       1  \n",
       "3            0.469120       0  \n",
       "4            0.395400       0  \n",
       "...               ...     ...  \n",
       "9995         0.481341       0  \n",
       "9996         0.508490       0  \n",
       "9997         0.210390       1  \n",
       "9998         0.464429       1  \n",
       "9999         0.190914       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = [\"CreditScore\", \"Age\", \"Balance\",'EstimatedSalary']\n",
    "scaler.fit(df[columns_to_scale])\n",
    "\n",
    "df[columns_to_scale] = scaler.transform(df[columns_to_scale])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning da idade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>0.538</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>0.516</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>0.304</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>0.698</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>0.842</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>0.332</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>0.718</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>0.844</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>0.884</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave        0.538    France  Female  0.0   \n",
       "1             2    15647311       Hill        0.516     Spain  Female  0.0   \n",
       "2             3    15619304       Onio        0.304    France  Female  0.0   \n",
       "3             4    15701354       Boni        0.698    France  Female  0.0   \n",
       "4             5    15737888   Mitchell        1.000     Spain  Female  0.0   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku        0.842    France    Male  0.0   \n",
       "9996       9997    15569892  Johnstone        0.332    France    Male  0.0   \n",
       "9997       9998    15584532        Liu        0.718    France  Female  0.0   \n",
       "9998       9999    15682355  Sabbatini        0.844   Germany    Male  0.0   \n",
       "9999      10000    15628319     Walker        0.884    France  Female  0.0   \n",
       "\n",
       "      Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2  0.000000              1          1               1   \n",
       "1          1  0.334031              1          0               1   \n",
       "2          8  0.636357              3          1               0   \n",
       "3          1  0.000000              2          0               0   \n",
       "4          2  0.500246              1          1               1   \n",
       "...      ...       ...            ...        ...             ...   \n",
       "9995       5  0.000000              2          1               0   \n",
       "9996      10  0.228657              1          1               1   \n",
       "9997       7  0.000000              1          0               1   \n",
       "9998       3  0.299226              2          1               0   \n",
       "9999       4  0.518708              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0            0.506735       1  \n",
       "1            0.562709       0  \n",
       "2            0.569654       1  \n",
       "3            0.469120       0  \n",
       "4            0.395400       0  \n",
       "...               ...     ...  \n",
       "9995         0.481341       0  \n",
       "9996         0.508490       0  \n",
       "9997         0.210390       1  \n",
       "9998         0.464429       1  \n",
       "9999         0.190914       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0,26,56,76,100]\n",
    "\n",
    "new_df = df[list((feature_columns)+(target_column))].copy()\n",
    "df['Age'] = pd.cut(new_df['Age'], bins=bins, labels=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engenharia de atributos - Dados Categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação dos dados categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>0.844</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography Gender  Age  \\\n",
       "0             1    15634602   Hargrave        0.538         0      0  0.0   \n",
       "1             2    15647311       Hill        0.516         1      0  0.0   \n",
       "2             3    15619304       Onio        0.304         0      0  0.0   \n",
       "3             4    15701354       Boni        0.698         0      0  0.0   \n",
       "4             5    15737888   Mitchell        1.000         1      0  0.0   \n",
       "...         ...         ...        ...          ...       ...    ...  ...   \n",
       "9995       9996    15606229   Obijiaku        0.842         0      1  0.0   \n",
       "9996       9997    15569892  Johnstone        0.332         0      1  0.0   \n",
       "9997       9998    15584532        Liu        0.718         0      0  0.0   \n",
       "9998       9999    15682355  Sabbatini        0.844         2      1  0.0   \n",
       "9999      10000    15628319     Walker        0.884         0      0  0.0   \n",
       "\n",
       "      Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2  0.000000              1          1               1   \n",
       "1          1  0.334031              1          0               1   \n",
       "2          8  0.636357              3          1               0   \n",
       "3          1  0.000000              2          0               0   \n",
       "4          2  0.500246              1          1               1   \n",
       "...      ...       ...            ...        ...             ...   \n",
       "9995       5  0.000000              2          1               0   \n",
       "9996      10  0.228657              1          1               1   \n",
       "9997       7  0.000000              1          0               1   \n",
       "9998       3  0.299226              2          1               0   \n",
       "9999       4  0.518708              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0            0.506735       1  \n",
       "1            0.562709       0  \n",
       "2            0.569654       1  \n",
       "3            0.469120       0  \n",
       "4            0.395400       0  \n",
       "...               ...     ...  \n",
       "9995         0.481341       0  \n",
       "9996         0.508490       0  \n",
       "9997         0.210390       1  \n",
       "9998         0.464429       1  \n",
       "9999         0.190914       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs = {}\n",
    "for column in categorical_columns:\n",
    "    vocabs[column] = UtilPreProcessor.creat_vocab(df[column])[0]\n",
    "    for i in range(len(df)):\n",
    "        df.loc[i,column] = UtilPreProcessor.get_index_vocab(vocabs[column],df.loc[i,column])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo com Validação Cruzada e *autokeras*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separação dos Dados em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.564</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.476786</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.540606</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.566554</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.277853</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.346880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.694</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.589523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography Gender  Age  Tenure   Balance  NumOfProducts  \\\n",
       "0           0.672         0      1  0.0       6  0.000000              2   \n",
       "1           0.564         2      1  0.0       4  0.476786              2   \n",
       "2           0.418         1      1  0.0       3  0.457317              1   \n",
       "3           0.422         0      0  0.0       9  0.540606              1   \n",
       "4           0.334         0      1  0.0       9  0.566554              1   \n",
       "...           ...       ...    ...  ...     ...       ...            ...   \n",
       "7995        0.836         0      1  0.0       8  0.277853              1   \n",
       "7996        0.664         0      0  0.0       1  0.000000              1   \n",
       "7997        0.770         0      0  0.0       1  0.000000              3   \n",
       "7998        0.634         0      1  0.0       8  0.758186              1   \n",
       "7999        0.694         2      1  0.0       1  0.589523              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1         0.895494       0  \n",
       "1             1               1         0.979930       0  \n",
       "2             1               0         0.429438       1  \n",
       "3             1               0         0.765417       1  \n",
       "4             0               0         0.197401       1  \n",
       "...         ...             ...              ...     ...  \n",
       "7995          1               1         0.346880       0  \n",
       "7996          1               1         0.003475       0  \n",
       "7997          0               0         0.461087       1  \n",
       "7998          1               0         0.487529       1  \n",
       "7999          1               1         0.267873       0  \n",
       "\n",
       "[8000 rows x 11 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df[feature_columns + target_column], test_size=0.2, random_state=42)\n",
    "df_train = df_train.reset_index().drop('index',axis=1)\n",
    "df_test = df_test.reset_index().drop('index',axis=1)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:23:42.218096: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7810 - loss: 0.5654 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7918 - loss: 0.5141 - val_accuracy: 0.8087 - val_loss: 0.4889\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7918 - loss: 0.5127 - val_accuracy: 0.8087 - val_loss: 0.4885\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7918 - loss: 0.5127 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7918 - loss: 0.5144 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7918 - loss: 0.5128 - val_accuracy: 0.8087 - val_loss: 0.4884\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7918 - loss: 0.5141 - val_accuracy: 0.8087 - val_loss: 0.4885\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7918 - loss: 0.5131 - val_accuracy: 0.8087 - val_loss: 0.4884\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7918 - loss: 0.5146 - val_accuracy: 0.8087 - val_loss: 0.4888\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7918 - loss: 0.5130 - val_accuracy: 0.8087 - val_loss: 0.4884\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7918 - loss: 0.5139 - val_accuracy: 0.8087 - val_loss: 0.4885\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7918 - loss: 0.5151 - val_accuracy: 0.8087 - val_loss: 0.4885\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7918 - loss: 0.5142 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7918 - loss: 0.5136 - val_accuracy: 0.8087 - val_loss: 0.4884\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.7918 - loss: 0.5122 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7918 - loss: 0.5125 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7918 - loss: 0.5126 - val_accuracy: 0.8087 - val_loss: 0.4887\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7918 - loss: 0.5125 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.7918 - loss: 0.5128 - val_accuracy: 0.8087 - val_loss: 0.4887\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7918 - loss: 0.5132 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.7918 - loss: 0.5135 - val_accuracy: 0.8087 - val_loss: 0.4885\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7918 - loss: 0.5118 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7918 - loss: 0.5124 - val_accuracy: 0.8087 - val_loss: 0.4887\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.7918 - loss: 0.5119 - val_accuracy: 0.8087 - val_loss: 0.4888\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7918 - loss: 0.5128 - val_accuracy: 0.8087 - val_loss: 0.4886\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7918 - loss: 0.5140 - val_accuracy: 0.8087 - val_loss: 0.4889\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7918 - loss: 0.5139 - val_accuracy: 0.8087 - val_loss: 0.4887\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7918 - loss: 0.5127 - val_accuracy: 0.8087 - val_loss: 0.4887\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7918 - loss: 0.5132 - val_accuracy: 0.8087 - val_loss: 0.4888\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7918 - loss: 0.5144 - val_accuracy: 0.8087 - val_loss: 0.4890\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7918 - loss: 0.5116 - val_accuracy: 0.8087 - val_loss: 0.4887\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7918 - loss: 0.5127 - val_accuracy: 0.8087 - val_loss: 0.4889\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7918 - loss: 0.5134 - val_accuracy: 0.8087 - val_loss: 0.4890\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.7918 - loss: 0.5133 - val_accuracy: 0.8087 - val_loss: 0.4888\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.7918 - loss: 0.5129 - val_accuracy: 0.8087 - val_loss: 0.4889\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7918 - loss: 0.5128 - val_accuracy: 0.8087 - val_loss: 0.4889\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.7918 - loss: 0.5125 - val_accuracy: 0.8087 - val_loss: 0.4888\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7918 - loss: 0.5134 - val_accuracy: 0.8087 - val_loss: 0.4889\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7918 - loss: 0.5118 - val_accuracy: 0.8087 - val_loss: 0.4889\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7918 - loss: 0.5127 - val_accuracy: 0.8087 - val_loss: 0.4888\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7918 - loss: 0.5137 - val_accuracy: 0.8087 - val_loss: 0.4890\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7918 - loss: 0.5121 - val_accuracy: 0.8087 - val_loss: 0.4889\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7918 - loss: 0.5131 - val_accuracy: 0.8087 - val_loss: 0.4888\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7918 - loss: 0.5132 - val_accuracy: 0.8087 - val_loss: 0.4890\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7918 - loss: 0.5137 - val_accuracy: 0.8087 - val_loss: 0.4890\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.7918 - loss: 0.5122 - val_accuracy: 0.8087 - val_loss: 0.4890\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7918 - loss: 0.5135 - val_accuracy: 0.8087 - val_loss: 0.4890\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7918 - loss: 0.5119 - val_accuracy: 0.8087 - val_loss: 0.4888\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7918 - loss: 0.5120 - val_accuracy: 0.8087 - val_loss: 0.4890\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.7918 - loss: 0.5136 - val_accuracy: 0.8087 - val_loss: 0.4887\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:24:03.139419: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7860 - loss: 0.5683 - val_accuracy: 0.7825 - val_loss: 0.5256\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7948 - loss: 0.5100 - val_accuracy: 0.7825 - val_loss: 0.5260\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.7948 - loss: 0.5098 - val_accuracy: 0.7825 - val_loss: 0.5261\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7948 - loss: 0.5092 - val_accuracy: 0.7825 - val_loss: 0.5257\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7948 - loss: 0.5099 - val_accuracy: 0.7825 - val_loss: 0.5256\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7948 - loss: 0.5075 - val_accuracy: 0.7825 - val_loss: 0.5260\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.7948 - loss: 0.5096 - val_accuracy: 0.7825 - val_loss: 0.5260\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7948 - loss: 0.5109 - val_accuracy: 0.7825 - val_loss: 0.5256\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7948 - loss: 0.5097 - val_accuracy: 0.7825 - val_loss: 0.5258\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7948 - loss: 0.5108 - val_accuracy: 0.7825 - val_loss: 0.5261\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7948 - loss: 0.5097 - val_accuracy: 0.7825 - val_loss: 0.5257\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.7948 - loss: 0.5083 - val_accuracy: 0.7825 - val_loss: 0.5257\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7948 - loss: 0.5101 - val_accuracy: 0.7825 - val_loss: 0.5257\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7948 - loss: 0.5087 - val_accuracy: 0.7825 - val_loss: 0.5251\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.7948 - loss: 0.5096 - val_accuracy: 0.7825 - val_loss: 0.5252\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.7948 - loss: 0.5098 - val_accuracy: 0.7825 - val_loss: 0.5251\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7948 - loss: 0.5105 - val_accuracy: 0.7825 - val_loss: 0.5251\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7948 - loss: 0.5090 - val_accuracy: 0.7825 - val_loss: 0.5255\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7948 - loss: 0.5098 - val_accuracy: 0.7825 - val_loss: 0.5250\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7948 - loss: 0.5091 - val_accuracy: 0.7825 - val_loss: 0.5253\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7948 - loss: 0.5095 - val_accuracy: 0.7825 - val_loss: 0.5248\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7948 - loss: 0.5096 - val_accuracy: 0.7825 - val_loss: 0.5249\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7948 - loss: 0.5091 - val_accuracy: 0.7825 - val_loss: 0.5250\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.7948 - loss: 0.5093 - val_accuracy: 0.7825 - val_loss: 0.5249\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7948 - loss: 0.5084 - val_accuracy: 0.7825 - val_loss: 0.5250\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7948 - loss: 0.5086 - val_accuracy: 0.7825 - val_loss: 0.5248\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.7948 - loss: 0.5094 - val_accuracy: 0.7825 - val_loss: 0.5248\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7948 - loss: 0.5094 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7948 - loss: 0.5095 - val_accuracy: 0.7825 - val_loss: 0.5248\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7948 - loss: 0.5098 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7948 - loss: 0.5083 - val_accuracy: 0.7825 - val_loss: 0.5247\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7948 - loss: 0.5099 - val_accuracy: 0.7825 - val_loss: 0.5247\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7948 - loss: 0.5096 - val_accuracy: 0.7825 - val_loss: 0.5248\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.7948 - loss: 0.5097 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7948 - loss: 0.5074 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7948 - loss: 0.5097 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7948 - loss: 0.5095 - val_accuracy: 0.7825 - val_loss: 0.5248\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7948 - loss: 0.5093 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7948 - loss: 0.5089 - val_accuracy: 0.7825 - val_loss: 0.5247\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.7948 - loss: 0.5086 - val_accuracy: 0.7825 - val_loss: 0.5247\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.7948 - loss: 0.5079 - val_accuracy: 0.7825 - val_loss: 0.5248\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7948 - loss: 0.5086 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7948 - loss: 0.5091 - val_accuracy: 0.7825 - val_loss: 0.5248\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7948 - loss: 0.5091 - val_accuracy: 0.7825 - val_loss: 0.5244\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.7948 - loss: 0.5080 - val_accuracy: 0.7825 - val_loss: 0.5245\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7948 - loss: 0.5075 - val_accuracy: 0.7825 - val_loss: 0.5245\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7948 - loss: 0.5085 - val_accuracy: 0.7825 - val_loss: 0.5247\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.7948 - loss: 0.5087 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.7948 - loss: 0.5095 - val_accuracy: 0.7825 - val_loss: 0.5247\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7948 - loss: 0.5093 - val_accuracy: 0.7825 - val_loss: 0.5246\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:24:23.107525: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7828 - loss: 0.5585 - val_accuracy: 0.7788 - val_loss: 0.5293\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7947 - loss: 0.5102 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.7947 - loss: 0.5112 - val_accuracy: 0.7788 - val_loss: 0.5297\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7947 - loss: 0.5096 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7947 - loss: 0.5087 - val_accuracy: 0.7788 - val_loss: 0.5294\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7947 - loss: 0.5104 - val_accuracy: 0.7788 - val_loss: 0.5295\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.7947 - loss: 0.5096 - val_accuracy: 0.7788 - val_loss: 0.5294\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7947 - loss: 0.5094 - val_accuracy: 0.7788 - val_loss: 0.5295\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7947 - loss: 0.5101 - val_accuracy: 0.7788 - val_loss: 0.5296\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7947 - loss: 0.5104 - val_accuracy: 0.7788 - val_loss: 0.5294\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7947 - loss: 0.5102 - val_accuracy: 0.7788 - val_loss: 0.5293\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7788 - val_loss: 0.5294\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7947 - loss: 0.5102 - val_accuracy: 0.7788 - val_loss: 0.5295\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7947 - loss: 0.5104 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.7947 - loss: 0.5094 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7947 - loss: 0.5104 - val_accuracy: 0.7788 - val_loss: 0.5295\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7947 - loss: 0.5098 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7947 - loss: 0.5091 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7947 - loss: 0.5088 - val_accuracy: 0.7788 - val_loss: 0.5293\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7947 - loss: 0.5091 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7947 - loss: 0.5089 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7947 - loss: 0.5091 - val_accuracy: 0.7788 - val_loss: 0.5294\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7947 - loss: 0.5089 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7947 - loss: 0.5093 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7947 - loss: 0.5093 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.7947 - loss: 0.5103 - val_accuracy: 0.7788 - val_loss: 0.5290\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7788 - val_loss: 0.5290\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.7947 - loss: 0.5098 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7947 - loss: 0.5095 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7947 - loss: 0.5079 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7947 - loss: 0.5089 - val_accuracy: 0.7788 - val_loss: 0.5290\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7947 - loss: 0.5089 - val_accuracy: 0.7788 - val_loss: 0.5290\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7788 - val_loss: 0.5290\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7947 - loss: 0.5088 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7947 - loss: 0.5092 - val_accuracy: 0.7788 - val_loss: 0.5289\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7947 - loss: 0.5097 - val_accuracy: 0.7788 - val_loss: 0.5293\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7947 - loss: 0.5087 - val_accuracy: 0.7788 - val_loss: 0.5293\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.7947 - loss: 0.5080 - val_accuracy: 0.7788 - val_loss: 0.5290\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7947 - loss: 0.5102 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7947 - loss: 0.5105 - val_accuracy: 0.7788 - val_loss: 0.5293\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7947 - loss: 0.5086 - val_accuracy: 0.7788 - val_loss: 0.5293\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7947 - loss: 0.5095 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7947 - loss: 0.5088 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7947 - loss: 0.5088 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7947 - loss: 0.5097 - val_accuracy: 0.7788 - val_loss: 0.5290\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.7947 - loss: 0.5093 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.7947 - loss: 0.5098 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.7947 - loss: 0.5086 - val_accuracy: 0.7788 - val_loss: 0.5292\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7947 - loss: 0.5087 - val_accuracy: 0.7788 - val_loss: 0.5290\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7788 - val_loss: 0.5291\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:24:43.672629: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7853 - loss: 0.5560 - val_accuracy: 0.7875 - val_loss: 0.5176\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.7947 - loss: 0.5089 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7947 - loss: 0.5099 - val_accuracy: 0.7875 - val_loss: 0.5178\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.7947 - loss: 0.5107 - val_accuracy: 0.7875 - val_loss: 0.5176\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.7947 - loss: 0.5098 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.7947 - loss: 0.5091 - val_accuracy: 0.7875 - val_loss: 0.5176\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7947 - loss: 0.5096 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7875 - val_loss: 0.5177\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.7947 - loss: 0.5098 - val_accuracy: 0.7875 - val_loss: 0.5177\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7947 - loss: 0.5093 - val_accuracy: 0.7875 - val_loss: 0.5177\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7947 - loss: 0.5092 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.7947 - loss: 0.5110 - val_accuracy: 0.7875 - val_loss: 0.5176\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7947 - loss: 0.5107 - val_accuracy: 0.7875 - val_loss: 0.5177\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7947 - loss: 0.5088 - val_accuracy: 0.7875 - val_loss: 0.5176\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7947 - loss: 0.5104 - val_accuracy: 0.7875 - val_loss: 0.5176\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7947 - loss: 0.5088 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.7947 - loss: 0.5097 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.7947 - loss: 0.5095 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.7947 - loss: 0.5093 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7947 - loss: 0.5089 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7947 - loss: 0.5095 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7947 - loss: 0.5084 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7947 - loss: 0.5092 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.7947 - loss: 0.5093 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7947 - loss: 0.5083 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7947 - loss: 0.5094 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.7947 - loss: 0.5092 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7947 - loss: 0.5082 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.7947 - loss: 0.5095 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7947 - loss: 0.5094 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.7947 - loss: 0.5081 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.7947 - loss: 0.5107 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7947 - loss: 0.5093 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7947 - loss: 0.5082 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7947 - loss: 0.5089 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.7947 - loss: 0.5095 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.7947 - loss: 0.5095 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7947 - loss: 0.5093 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7947 - loss: 0.5091 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7947 - loss: 0.5095 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7947 - loss: 0.5105 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.7947 - loss: 0.5083 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7947 - loss: 0.5087 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7947 - loss: 0.5108 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7947 - loss: 0.5108 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.7947 - loss: 0.5084 - val_accuracy: 0.7875 - val_loss: 0.5175\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7947 - loss: 0.5090 - val_accuracy: 0.7875 - val_loss: 0.5174\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:25:04.339692: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7848 - loss: 0.5423 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.7916 - loss: 0.5149 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.7916 - loss: 0.5126 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.7916 - loss: 0.5149 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.7916 - loss: 0.5141 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7916 - loss: 0.5153 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7916 - loss: 0.5127 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7916 - loss: 0.5139 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7916 - loss: 0.5129 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7916 - loss: 0.5131 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7916 - loss: 0.5125 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7916 - loss: 0.5143 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.7916 - loss: 0.5134 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.7916 - loss: 0.5132 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7916 - loss: 0.5144 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7916 - loss: 0.5160 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7916 - loss: 0.5137 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.7916 - loss: 0.5135 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7916 - loss: 0.5143 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7916 - loss: 0.5127 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.7916 - loss: 0.5128 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7916 - loss: 0.5131 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.7916 - loss: 0.5136 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.7916 - loss: 0.5118 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7916 - loss: 0.5142 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.7916 - loss: 0.5133 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.7916 - loss: 0.5142 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7916 - loss: 0.5153 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7916 - loss: 0.5129 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.7916 - loss: 0.5140 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7916 - loss: 0.5130 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.7916 - loss: 0.5130 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7916 - loss: 0.5125 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7916 - loss: 0.5133 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.7916 - loss: 0.5129 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7916 - loss: 0.5136 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7916 - loss: 0.5134 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7916 - loss: 0.5134 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7916 - loss: 0.5134 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7916 - loss: 0.5124 - val_accuracy: 0.8012 - val_loss: 0.4987\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.7916 - loss: 0.5133 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7916 - loss: 0.5122 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7916 - loss: 0.5120 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.7916 - loss: 0.5134 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7916 - loss: 0.5119 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.7916 - loss: 0.5141 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7916 - loss: 0.5127 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7916 - loss: 0.5138 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.7916 - loss: 0.5122 - val_accuracy: 0.8012 - val_loss: 0.4989\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.7916 - loss: 0.5130 - val_accuracy: 0.8012 - val_loss: 0.4988\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:25:24.572895: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7782 - loss: 0.5662 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7944 - loss: 0.5107 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7944 - loss: 0.5108 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7944 - loss: 0.5111 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.7944 - loss: 0.5102 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7944 - loss: 0.5106 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7944 - loss: 0.5107 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.7944 - loss: 0.5088 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7944 - loss: 0.5098 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.7944 - loss: 0.5104 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.7944 - loss: 0.5087 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.7944 - loss: 0.5091 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.7944 - loss: 0.5097 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.7944 - loss: 0.5103 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.7944 - loss: 0.5102 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.7944 - loss: 0.5092 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.7944 - loss: 0.5088 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.7944 - loss: 0.5094 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7944 - loss: 0.5096 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.5097 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.7944 - loss: 0.5104 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.7944 - loss: 0.5090 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.7944 - loss: 0.5105 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.7944 - loss: 0.5092 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.7944 - loss: 0.5103 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.5095 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.7944 - loss: 0.5101 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.7944 - loss: 0.5098 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.5090 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.7944 - loss: 0.5103 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.7944 - loss: 0.5094 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.7944 - loss: 0.5098 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7944 - loss: 0.5101 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.7944 - loss: 0.5104 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.5093 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.7944 - loss: 0.5096 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7944 - loss: 0.5087 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.7944 - loss: 0.5103 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7944 - loss: 0.5091 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7944 - loss: 0.5101 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7944 - loss: 0.5099 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7944 - loss: 0.5107 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.7944 - loss: 0.5093 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.7944 - loss: 0.5098 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7944 - loss: 0.5098 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7944 - loss: 0.5099 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7944 - loss: 0.5102 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.7944 - loss: 0.5100 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7944 - loss: 0.5097 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7944 - loss: 0.5082 - val_accuracy: 0.7950 - val_loss: 0.5073\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:25:46.495885: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7730 - loss: 0.5604 - val_accuracy: 0.7800 - val_loss: 0.5299\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.7946 - loss: 0.5118 - val_accuracy: 0.7800 - val_loss: 0.5297\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.7946 - loss: 0.5104 - val_accuracy: 0.7800 - val_loss: 0.5296\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7946 - loss: 0.5108 - val_accuracy: 0.7800 - val_loss: 0.5295\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7946 - loss: 0.5097 - val_accuracy: 0.7800 - val_loss: 0.5302\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7946 - loss: 0.5094 - val_accuracy: 0.7800 - val_loss: 0.5294\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7946 - loss: 0.5112 - val_accuracy: 0.7800 - val_loss: 0.5300\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7946 - loss: 0.5116 - val_accuracy: 0.7800 - val_loss: 0.5300\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7946 - loss: 0.5112 - val_accuracy: 0.7800 - val_loss: 0.5298\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.7946 - loss: 0.5087 - val_accuracy: 0.7800 - val_loss: 0.5296\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7946 - loss: 0.5098 - val_accuracy: 0.7800 - val_loss: 0.5293\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7946 - loss: 0.5094 - val_accuracy: 0.7800 - val_loss: 0.5295\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.7946 - loss: 0.5094 - val_accuracy: 0.7800 - val_loss: 0.5294\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7946 - loss: 0.5100 - val_accuracy: 0.7800 - val_loss: 0.5290\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7946 - loss: 0.5093 - val_accuracy: 0.7800 - val_loss: 0.5289\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7946 - loss: 0.5095 - val_accuracy: 0.7800 - val_loss: 0.5289\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7946 - loss: 0.5091 - val_accuracy: 0.7800 - val_loss: 0.5288\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.7946 - loss: 0.5109 - val_accuracy: 0.7800 - val_loss: 0.5286\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.7946 - loss: 0.5099 - val_accuracy: 0.7800 - val_loss: 0.5286\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.7946 - loss: 0.5097 - val_accuracy: 0.7800 - val_loss: 0.5288\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7946 - loss: 0.5099 - val_accuracy: 0.7800 - val_loss: 0.5283\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7946 - loss: 0.5096 - val_accuracy: 0.7800 - val_loss: 0.5284\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.5095 - val_accuracy: 0.7800 - val_loss: 0.5285\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.7946 - loss: 0.5094 - val_accuracy: 0.7800 - val_loss: 0.5282\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.7946 - loss: 0.5097 - val_accuracy: 0.7800 - val_loss: 0.5284\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7946 - loss: 0.5088 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7946 - loss: 0.5091 - val_accuracy: 0.7800 - val_loss: 0.5283\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7946 - loss: 0.5087 - val_accuracy: 0.7800 - val_loss: 0.5280\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.5092 - val_accuracy: 0.7800 - val_loss: 0.5280\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.5095 - val_accuracy: 0.7800 - val_loss: 0.5284\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.5103 - val_accuracy: 0.7800 - val_loss: 0.5283\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.7946 - loss: 0.5094 - val_accuracy: 0.7800 - val_loss: 0.5283\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.7946 - loss: 0.5080 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.7946 - loss: 0.5083 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.7946 - loss: 0.5107 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.7946 - loss: 0.5090 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7946 - loss: 0.5088 - val_accuracy: 0.7800 - val_loss: 0.5283\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.7946 - loss: 0.5091 - val_accuracy: 0.7800 - val_loss: 0.5284\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.7946 - loss: 0.5093 - val_accuracy: 0.7800 - val_loss: 0.5279\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.7946 - loss: 0.5088 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.7946 - loss: 0.5089 - val_accuracy: 0.7800 - val_loss: 0.5282\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.5082 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.5103 - val_accuracy: 0.7800 - val_loss: 0.5282\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.5091 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.7946 - loss: 0.5093 - val_accuracy: 0.7800 - val_loss: 0.5280\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7946 - loss: 0.5107 - val_accuracy: 0.7800 - val_loss: 0.5283\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.7946 - loss: 0.5087 - val_accuracy: 0.7800 - val_loss: 0.5281\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7946 - loss: 0.5089 - val_accuracy: 0.7800 - val_loss: 0.5280\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7946 - loss: 0.5079 - val_accuracy: 0.7800 - val_loss: 0.5280\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7946 - loss: 0.5086 - val_accuracy: 0.7800 - val_loss: 0.5282\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:26:07.685712: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7852 - loss: 0.5598 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7936 - loss: 0.5120 - val_accuracy: 0.7900 - val_loss: 0.5149\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.7936 - loss: 0.5106 - val_accuracy: 0.7900 - val_loss: 0.5149\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.7936 - loss: 0.5117 - val_accuracy: 0.7900 - val_loss: 0.5148\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7936 - loss: 0.5113 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.7936 - loss: 0.5109 - val_accuracy: 0.7900 - val_loss: 0.5148\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.7936 - loss: 0.5118 - val_accuracy: 0.7900 - val_loss: 0.5149\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7936 - loss: 0.5115 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.7936 - loss: 0.5108 - val_accuracy: 0.7900 - val_loss: 0.5147\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7936 - loss: 0.5119 - val_accuracy: 0.7900 - val_loss: 0.5149\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.7936 - loss: 0.5105 - val_accuracy: 0.7900 - val_loss: 0.5147\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7936 - loss: 0.5103 - val_accuracy: 0.7900 - val_loss: 0.5147\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.7936 - loss: 0.5093 - val_accuracy: 0.7900 - val_loss: 0.5149\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.7936 - loss: 0.5106 - val_accuracy: 0.7900 - val_loss: 0.5150\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.7936 - loss: 0.5111 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7936 - loss: 0.5106 - val_accuracy: 0.7900 - val_loss: 0.5147\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7936 - loss: 0.5112 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.7936 - loss: 0.5110 - val_accuracy: 0.7900 - val_loss: 0.5147\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.7936 - loss: 0.5106 - val_accuracy: 0.7900 - val_loss: 0.5147\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7936 - loss: 0.5115 - val_accuracy: 0.7900 - val_loss: 0.5147\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7936 - loss: 0.5100 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.7936 - loss: 0.5099 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7936 - loss: 0.5107 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.7936 - loss: 0.5101 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.7936 - loss: 0.5103 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.7936 - loss: 0.5104 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.7936 - loss: 0.5106 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.7936 - loss: 0.5123 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.7936 - loss: 0.5089 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7936 - loss: 0.5097 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.7936 - loss: 0.5101 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7936 - loss: 0.5116 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7936 - loss: 0.5099 - val_accuracy: 0.7900 - val_loss: 0.5144\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.7936 - loss: 0.5105 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.7936 - loss: 0.5114 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7936 - loss: 0.5109 - val_accuracy: 0.7900 - val_loss: 0.5146\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7936 - loss: 0.5106 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.7936 - loss: 0.5114 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.7936 - loss: 0.5105 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7936 - loss: 0.5110 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.7936 - loss: 0.5099 - val_accuracy: 0.7900 - val_loss: 0.5144\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.7936 - loss: 0.5108 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7936 - loss: 0.5106 - val_accuracy: 0.7900 - val_loss: 0.5144\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.7936 - loss: 0.5108 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.7936 - loss: 0.5114 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.7936 - loss: 0.5110 - val_accuracy: 0.7900 - val_loss: 0.5145\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.7936 - loss: 0.5113 - val_accuracy: 0.7900 - val_loss: 0.5144\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7936 - loss: 0.5113 - val_accuracy: 0.7900 - val_loss: 0.5144\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.7936 - loss: 0.5110 - val_accuracy: 0.7900 - val_loss: 0.5143\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.7936 - loss: 0.5106 - val_accuracy: 0.7900 - val_loss: 0.5144\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:26:27.831642: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7891 - loss: 0.5600 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7922 - loss: 0.5129 - val_accuracy: 0.8075 - val_loss: 0.4903\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.7922 - loss: 0.5130 - val_accuracy: 0.8075 - val_loss: 0.4903\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.7922 - loss: 0.5121 - val_accuracy: 0.8075 - val_loss: 0.4902\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.7922 - loss: 0.5133 - val_accuracy: 0.8075 - val_loss: 0.4902\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7922 - loss: 0.5127 - val_accuracy: 0.8075 - val_loss: 0.4901\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.7922 - loss: 0.5139 - val_accuracy: 0.8075 - val_loss: 0.4902\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7922 - loss: 0.5141 - val_accuracy: 0.8075 - val_loss: 0.4902\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.7922 - loss: 0.5129 - val_accuracy: 0.8075 - val_loss: 0.4903\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7922 - loss: 0.5141 - val_accuracy: 0.8075 - val_loss: 0.4903\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.7922 - loss: 0.5120 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7922 - loss: 0.5127 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.7922 - loss: 0.5135 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.7922 - loss: 0.5130 - val_accuracy: 0.8075 - val_loss: 0.4902\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.7922 - loss: 0.5135 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7922 - loss: 0.5134 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7922 - loss: 0.5137 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.7922 - loss: 0.5155 - val_accuracy: 0.8075 - val_loss: 0.4903\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.7922 - loss: 0.5129 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.7922 - loss: 0.5124 - val_accuracy: 0.8075 - val_loss: 0.4905\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7922 - loss: 0.5123 - val_accuracy: 0.8075 - val_loss: 0.4905\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7922 - loss: 0.5116 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.7922 - loss: 0.5128 - val_accuracy: 0.8075 - val_loss: 0.4905\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7922 - loss: 0.5124 - val_accuracy: 0.8075 - val_loss: 0.4905\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.7922 - loss: 0.5124 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.7922 - loss: 0.5132 - val_accuracy: 0.8075 - val_loss: 0.4905\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7922 - loss: 0.5127 - val_accuracy: 0.8075 - val_loss: 0.4905\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7922 - loss: 0.5117 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.7922 - loss: 0.5123 - val_accuracy: 0.8075 - val_loss: 0.4907\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.7922 - loss: 0.5122 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.7922 - loss: 0.5116 - val_accuracy: 0.8075 - val_loss: 0.4907\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.7922 - loss: 0.5137 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.7922 - loss: 0.5121 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7922 - loss: 0.5116 - val_accuracy: 0.8075 - val_loss: 0.4904\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.7922 - loss: 0.5125 - val_accuracy: 0.8075 - val_loss: 0.4905\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7922 - loss: 0.5134 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.7922 - loss: 0.5129 - val_accuracy: 0.8075 - val_loss: 0.4908\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.7922 - loss: 0.5135 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.7922 - loss: 0.5115 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7922 - loss: 0.5115 - val_accuracy: 0.8075 - val_loss: 0.4908\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7922 - loss: 0.5115 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.7922 - loss: 0.5125 - val_accuracy: 0.8075 - val_loss: 0.4907\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7922 - loss: 0.5108 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.7922 - loss: 0.5126 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.7922 - loss: 0.5125 - val_accuracy: 0.8075 - val_loss: 0.4907\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7922 - loss: 0.5126 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.7922 - loss: 0.5128 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.7922 - loss: 0.5124 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7922 - loss: 0.5131 - val_accuracy: 0.8075 - val_loss: 0.4906\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7922 - loss: 0.5131 - val_accuracy: 0.8075 - val_loss: 0.4907\n",
      "Reloading Tuner from ./auto_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:26:48.220696: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7904 - loss: 0.5641 - val_accuracy: 0.8138 - val_loss: 0.4814\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.7921 - loss: 0.5123 - val_accuracy: 0.8138 - val_loss: 0.4814\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.7921 - loss: 0.5146 - val_accuracy: 0.8138 - val_loss: 0.4815\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7921 - loss: 0.5127 - val_accuracy: 0.8138 - val_loss: 0.4814\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.7921 - loss: 0.5119 - val_accuracy: 0.8138 - val_loss: 0.4815\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.7921 - loss: 0.5125 - val_accuracy: 0.8138 - val_loss: 0.4813\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.7921 - loss: 0.5126 - val_accuracy: 0.8138 - val_loss: 0.4815\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.7921 - loss: 0.5131 - val_accuracy: 0.8138 - val_loss: 0.4815\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7921 - loss: 0.5114 - val_accuracy: 0.8138 - val_loss: 0.4816\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.7921 - loss: 0.5130 - val_accuracy: 0.8138 - val_loss: 0.4818\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.7921 - loss: 0.5138 - val_accuracy: 0.8138 - val_loss: 0.4815\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.7921 - loss: 0.5138 - val_accuracy: 0.8138 - val_loss: 0.4814\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.7921 - loss: 0.5125 - val_accuracy: 0.8138 - val_loss: 0.4815\n",
      "Epoch 14/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7921 - loss: 0.5127 - val_accuracy: 0.8138 - val_loss: 0.4817\n",
      "Epoch 15/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7921 - loss: 0.5129 - val_accuracy: 0.8138 - val_loss: 0.4816\n",
      "Epoch 16/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.7921 - loss: 0.5131 - val_accuracy: 0.8138 - val_loss: 0.4816\n",
      "Epoch 17/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.7921 - loss: 0.5128 - val_accuracy: 0.8138 - val_loss: 0.4818\n",
      "Epoch 18/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.7921 - loss: 0.5134 - val_accuracy: 0.8138 - val_loss: 0.4819\n",
      "Epoch 19/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7921 - loss: 0.5123 - val_accuracy: 0.8138 - val_loss: 0.4821\n",
      "Epoch 20/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.7921 - loss: 0.5148 - val_accuracy: 0.8138 - val_loss: 0.4819\n",
      "Epoch 21/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.7921 - loss: 0.5124 - val_accuracy: 0.8138 - val_loss: 0.4822\n",
      "Epoch 22/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.7921 - loss: 0.5136 - val_accuracy: 0.8138 - val_loss: 0.4818\n",
      "Epoch 23/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7921 - loss: 0.5122 - val_accuracy: 0.8138 - val_loss: 0.4822\n",
      "Epoch 24/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7921 - loss: 0.5132 - val_accuracy: 0.8138 - val_loss: 0.4820\n",
      "Epoch 25/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.7921 - loss: 0.5131 - val_accuracy: 0.8138 - val_loss: 0.4821\n",
      "Epoch 26/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.7921 - loss: 0.5114 - val_accuracy: 0.8138 - val_loss: 0.4821\n",
      "Epoch 27/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.7921 - loss: 0.5131 - val_accuracy: 0.8138 - val_loss: 0.4819\n",
      "Epoch 28/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.7921 - loss: 0.5136 - val_accuracy: 0.8138 - val_loss: 0.4820\n",
      "Epoch 29/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.7921 - loss: 0.5122 - val_accuracy: 0.8138 - val_loss: 0.4820\n",
      "Epoch 30/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.7921 - loss: 0.5119 - val_accuracy: 0.8138 - val_loss: 0.4821\n",
      "Epoch 31/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7921 - loss: 0.5116 - val_accuracy: 0.8138 - val_loss: 0.4820\n",
      "Epoch 32/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7921 - loss: 0.5134 - val_accuracy: 0.8138 - val_loss: 0.4821\n",
      "Epoch 33/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.7921 - loss: 0.5131 - val_accuracy: 0.8138 - val_loss: 0.4821\n",
      "Epoch 34/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.7921 - loss: 0.5124 - val_accuracy: 0.8138 - val_loss: 0.4823\n",
      "Epoch 35/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7921 - loss: 0.5125 - val_accuracy: 0.8138 - val_loss: 0.4824\n",
      "Epoch 36/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.7921 - loss: 0.5128 - val_accuracy: 0.8138 - val_loss: 0.4820\n",
      "Epoch 37/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.7921 - loss: 0.5126 - val_accuracy: 0.8138 - val_loss: 0.4823\n",
      "Epoch 38/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.7921 - loss: 0.5141 - val_accuracy: 0.8138 - val_loss: 0.4823\n",
      "Epoch 39/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.7921 - loss: 0.5125 - val_accuracy: 0.8138 - val_loss: 0.4822\n",
      "Epoch 40/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.7921 - loss: 0.5138 - val_accuracy: 0.8138 - val_loss: 0.4822\n",
      "Epoch 41/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.7921 - loss: 0.5128 - val_accuracy: 0.8138 - val_loss: 0.4821\n",
      "Epoch 42/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.7921 - loss: 0.5132 - val_accuracy: 0.8138 - val_loss: 0.4823\n",
      "Epoch 43/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.7921 - loss: 0.5110 - val_accuracy: 0.8138 - val_loss: 0.4823\n",
      "Epoch 44/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7921 - loss: 0.5124 - val_accuracy: 0.8138 - val_loss: 0.4823\n",
      "Epoch 45/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.7921 - loss: 0.5116 - val_accuracy: 0.8138 - val_loss: 0.4822\n",
      "Epoch 46/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7921 - loss: 0.5121 - val_accuracy: 0.8138 - val_loss: 0.4822\n",
      "Epoch 47/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.7921 - loss: 0.5120 - val_accuracy: 0.8138 - val_loss: 0.4822\n",
      "Epoch 48/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.7921 - loss: 0.5122 - val_accuracy: 0.8138 - val_loss: 0.4823\n",
      "Epoch 49/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.7921 - loss: 0.5116 - val_accuracy: 0.8138 - val_loss: 0.4824\n",
      "Epoch 50/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7921 - loss: 0.5118 - val_accuracy: 0.8138 - val_loss: 0.4822\n"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "auto_models = []\n",
    "for train_index, test_index in kf.split(df_train):\n",
    "    train_df = df_train.iloc[train_index]\n",
    "    val_df = df_train.iloc[test_index]  \n",
    "    automodel = ak.AutoModel(\n",
    "        ak.Input(),\n",
    "        ak.ClassificationHead(),\n",
    "    )\n",
    "    automodel.fit(train_df[feature_columns].values.astype(float),\n",
    "                  train_df[target_column].values.astype(float), \n",
    "                  epochs=50,\n",
    "                  validation_data = (val_df[feature_columns].values.astype(float),\n",
    "                                      val_df[target_column].values.astype(float)))\n",
    "    auto_models.append(automodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.8026 - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.8026 - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.8026 - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.8026 - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8026 - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 152ms/step - accuracy: 0.8125 - loss: 0.4830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8026 - loss: 0.4968\n",
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.8026 - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.8026 - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.8026 - loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49553826451301575, 0.8034999966621399]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.8026 - loss: 0.4968\n",
      "[0.49553826451301575, 0.8034999966621399]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabio/venvs/my_venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "for automodel in auto_models:\n",
    "    print(automodel.evaluate(df_test[feature_columns].values.astype(float), df_test[target_column].values.astype(float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor resultado obtido na atividade 3 foi de 80% de acurácia, enquanto utilizando Auto-ML com *autokeras* foi de 80,26%. Neste *dataset*, ao utilizar a mesma etapa de pré-processamento da atividade 3, a ferramenta de Auto-ML *autokeras* não conseguiu melhorar siginficativamente os resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
